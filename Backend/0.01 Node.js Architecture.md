#### **Core Architecture: The Single-Threaded Event Loop**
- Node.js uses a **single-threaded event loop** that executes JavaScript and manages callbacks
- For I/O operations, it never blocks the main thread, instead, it delegates to the **libuv** library
- **Libuv**, a cross-platform C library that implements Node.js’s event loop and async I/O, provides a unified abstraction over different OS mechanisms:
    - Linux: `epoll` (readiness-based)
    - macOS: `kqueue` (readiness-based)
    - Windows: `IOCP` (completion-based)
- This model excels at I/O-bound workloads, one thread can handle thousands of concurrent connections without thread management overhead

<hr class="hr-light" />

#### **Demystifying the "Single-Threaded" Model**
**Node.js is single-threaded ONLY for JavaScript execution**, but uses **multiple threads** and **kernel async facilities** under the hood.

**It Actually Uses Three Concurrency Models:**
1. **Single Thread** (JavaScript Execution)
    ```javascript
    // This part runs in one thread
	app.get('/data', (req, res) => {
	    const user = getUserSync();  // Blocks this thread
	    res.json(user);
	});
    ```
    
2. **Thread Pool** (File I/O, DNS, Crypto - via libuv "The Blocking Operations")
    ```javascript
    // These use libuv's thread pool (default: 4 threads)
	fs.readFile('large.txt', () => {});    // Thread 1
	crypto.pbkdf2('pass', () => {});       // Thread 2  
	dns.lookup('google.com', () => {});    // Thread 3
	fs.writeFile('log.txt', () => {});     // Thread 4
	fs.readFile('another.txt', () => {});  // QUEUED! (Thread pool full)
    ```
3. **Kernel Async** (Network I/O - true async via OS)
	```javascript
	// These use OS-level async (NO threads needed)
	http.createServer();      // Kernel handles connections
	socket.connect();         // OS manages network queues
	fetch('https://api.com'); // OS handles DNS + TCP
	```

**Visualization:**
```text
┌────────────────────────────────────────────────────────────────┐
│                         Node.js Process                        │
├────────────────────────────────────────────────────────────────┤
│  ┌─────────────────┐  ┌──────────────────────────────────────┐ │
│  │ JavaScript Main │  │          libuv Thread Pool           │ │
|  |     Thread      |  |        (4 Threads by Default)        | |
│  │ • Your Code     │  │  ┌─────-┐ ┌─────-┐ ┌─────-┐ ┌─────-┐ │ │
│  │ • Event Loop    │  │  │Thread│ │Thread│ │Thread│ │Thread│ │ │
│  │ • Callbacks     │  │  │  1   │ │  2   │ │  3   │ │  4   │ │ │
│  │                 │  │  └─────-┘ └─────-┘ └─────-┘ └────-─┘ │ │
│  └─────────────────┘  └──────────────────────────────────────┘ │
├────────────────────────────────────────────────────────────────┤
│          libuv Event Loop + Kernel Integration                 │
│  ┌───────────────────────────────────────────────────────────┐ │
│  │              OS Kernel (epoll/kqueue/IOCP)                │ │
│  │  • Manages 10,000+ network connections                    │ │
│  │  • Handles TCP handshakes, packet queuing                 │ │
│  │  • Wakes Node.js ONLY when data is ready                  │ │
│  └───────────────────────────────────────────────────────────┘ │
└────────────────────────────────────────────────────────────────┘
```

<hr class="hr-light" />

#### **How Network Listening REALLY Works**
Node.js doesn’t actively wait for connections the OS handles that, and the event loop simply wakes up when there’s work to do.

```c
// What actually happens in libuv:
int uv_run(uv_loop_t* loop) {
    while (running) {
        // 1. Check timers
        uv__update_time(loop);
        uv__run_timers(loop);
        
        // 2. Poll for events WITH TIMEOUT
        timeout = uv_backend_timeout(loop);
        uv__io_poll(loop, timeout);  // ← THREAD SLEEPS HERE!
        
        // 3. Run callbacks for ready events
        uv__run_pending(loop);
        uv__run_idle(loop);
        uv__run_prepare(loop);
    }
}
```

**What Happens Inside `uv__io_poll()`:**
- **Thread blocks** in this system call (`epoll_wait()`, `kqueue()`, or `GetQueuedCompletionStatus`)
- **CPU usage drops to 0%** - thread is effectively "asleep"
- **OS kernel manages** all network connections internally
- **OS wakes the thread** when:
    - New TCP connection arrives
    - Data is ready on existing sockets
    - Timer expires
    - File I/O completes from thread pool

**Visualizing Connection Flow:**
```text
┌─────────────┐    ┌──────────────────┐    ┌──────────────┐
│   Client    │    │   OS Kernel      │    │   Node.js    │
│             │    │                  │    │              │
│ "Connect to │───▶│ • Accepts SYN    │    │              │
│ port 3000"  │    │ • Completes TCP  │    │ Thread       │
│             │    │    handshake     │───▶│ SLEEPING in  │
│             │    │ • Queues packet  │    │ uv__io_poll()│
│             │    │ • Wakes Node.js  │    │              │
└─────────────┘    └──────────────────┘    └──────────────┘
         │                      │                      │
         │    "I'll handle      │    "Hey! New         │ "Thanks! I'll
         │    the waiting"      │    connection!"      │  process it"
         └─────────────────────▶│◀─────────────────────┘
```

**Proof: One Thread Handling Massive Concurrency**
```javascript
const http = require('http');
const server = http.createServer((req, res) => {
    res.end('Hello World');
});

server.listen(3000, () => {
    console.log('Server listening...');
    
    // Prove thread is NOT busy waiting
    setInterval(() => {
        // This runs regularly proving thread is free
        console.log(`[${new Date().toISOString()}] Thread is free!`);
    }, 1000);
});

// Run this and make 10,000 simultaneous connections
// Watch: CPU stays near 0%, thread remains responsive
```

- **No busy-waiting** - thread sleeps efficiently
- **OS does the heavy lifting** - kernel handles TCP stacks, connection queues
- **Scalability** - one thread can manage 100,000+ connections
- **Zero CPU during idle** - unlike traditional "while true accept()" loops

---

#### **The Complete Node.js Architecture Stack**

**Bootstrapping Process:**  
When you run `node app.js`, Node initializes in this order:
1. Load V8 and initialize the JavaScript engine isolate
2. Initialize libuv event loop and thread pool
3. Load built-in C++ modules and bindings
4. Execute your JavaScript code in the main context
5. Start the event loop

**Architectural Layers:**
```text
┌────────────────────────────┐
│    Your JavaScript Code    │
├────────────────────────────┤
│   Node Core Modules (fs,   │
│   net, http, crypto, etc.) │
├────────────────────────────┤
│   C++ Bindings + N-API     │
│   (Timers, Buffer, etc.)   │
├────────────────────────────┤
│   V8 Engine (Executes JS)  │
├────────────────────────────┤
│   libuv (Event Loop +      │
│   Thread Pool)             │
├────────────────────────────┤
│   OS Kernel Async APIs     │
│   (epoll, IOCP, kqueue)    │
└────────────────────────────┘
```

**Event Loop Phase Details:**
The libuv event loop processes tasks in specific phases:
```text
┌───────────────────────────┐
│   timers (setTimeout)     │ ← Executes scheduled timer callbacks
│   pending callbacks       │ ← System operations (TCP errors, etc.)
│   idle, prepare           │ ← Internal libuv housekeeping  
│   poll (I/O callbacks)    │ ← Most I/O operations processed here (Most time spent here)
│   check (setImmediate)    │ ← setImmediate() callbacks execute
│   close callbacks         │ ← Socket close, handle cleanup
└───────────────────────────┘
```

<hr class="hr-light" />

#### **How Async I/O Actually Works (The Two OS Models)**

**Readiness Model (Linux/macOS)**
- **Two-step process:** first ask the OS "which sockets have data ready?", then perform the actual I/O operation
- You get notified when data is _available to read_, then call `read()` to move it from kernel to user space
- There's still a system call, but you only make it when you know it won't block

**Completion Model (Windows IOCP, Linux io_uring)**
- **Single-step process:** Submit I/O request with your buffer —> OS handles everything —> Get notified when data is _already in your buffer_
- More efficient but more complex to implement
- Linux's `io_uring` brings true completion-based async to Linux

<hr class="hr-light" />

#### **Node.js's Dual Async Strategy**

**1. True Kernel-Level Async (Network/Sockets)**
- **Flow:** Register socket with OS —> Continue executing code —> OS notifies when data ready —> Libuv queues callback —> Event loop executes it
- Uses the OS's native async facilities directly
- **Why it's efficient:** no additional threads needed, pure event-driven architecture

**2. Simulated Async via Thread Pool (Files, DNS, Crypto)**
- **The reality:** despite the "single-threaded" reputation, Node.js uses a **thread pool** for operations the OS doesn't handle well asynchronously
- **Flow:** Submit task to thread pool —> Worker thread executes _blocking_ system call —> Thread submits callback —> Event loop executes it
- **Purpose:** prevents blocking the main event loop with operations that would otherwise stall it

**The C++ Bindings Bridge:**
- Node's standard library (fs, net, crypto, dns) is implemented in C++, not JavaScript
- When you call `fs.readFile()`, it goes through this flow: JavaScript —> C++ binding —> Libuv (thread pool) —> Callback queued —> Event loop executes
- This bridge lets JavaScript access OS-level system calls safely and asynchronously via libuv

**Operations That Force Thread Pool Usage:**
- **File System I/O** (`fs.readFile`) - because filesystem APIs are often blocking
- **DNS resolution** (`dns.lookup`) - because `getaddrinfo` is blocking and may read local files like `/etc/hosts`
- **CPU-intensive crypto operations** - to avoid freezing the main thread
- **All `Worker Threads` tasks** - user-defined background work
- **Native add-ons** - custom C++ modules using N-API

##### **Thread Pool Saturation**
**Critical Problem:** default thread pool has only **4 threads**
- If you have 4 long-running operations + 1 more request, the 5th operation queues up
- Your application appears "blocked" even with an idle event loop
- **DNS is particularly dangerous:** every `fetch()` or HTTP request starts with a DNS lookup that hits the thread pool

```javascript
// Real-world example of thread pool saturation
const fs = require('fs');
const https = require('https');

// These 5 file operations will bottleneck
fs.readFile('large1.txt', () => {}); // Thread 1
fs.readFile('large2.txt', () => {}); // Thread 2  
fs.readFile('large3.txt', () => {}); // Thread 3
fs.readFile('large4.txt', () => {}); // Thread 4
fs.readFile('large5.txt', () => {}); // Queued - waits for free thread

// Each HTTP call also uses thread pool for DNS resolution!
https.get('https://api1.com', () => {});
https.get('https://api2.com', () => {});
```

**Performance Solutions:**
- Increase thread pool size: `UV_THREADPOOL_SIZE=16 node app.js`
- Use `dns.resolve` for network-only DNS (bypasses thread pool)
- Be mindful of mixed workloads (files + DNS + crypto)

<hr class="hr-light" />

#### **Advanced Node.js Concurrency & Observability**

**Concurrency Primitives Beyond Libuv:**
- **Worker Threads:** in-process threads for CPU-bound JavaScript without blocking event loop
- **Child Processes:** independent OS processes for running separate Node instances
- **Cluster Module:** multi-process load balancing across CPU cores

**Diagnostics & Observability:**
- **async_hooks:** trace async resource lifecycles and dependencies
- **perf_hooks:** measure performance metrics and timing
- **inspector:** Chrome DevTools Protocol integration for debugging
- **trace_events:** low-level tracing of libuv, garbage collection, and async operations

**Native Extensions (N-API):**
- C API for building native add-ons that can call OS-level APIs directly
- Run C/C++ performance-critical code alongside JavaScript
- Access Node internals like the libuv event loop directly

**The Complete Insight:** Node's async model is actually hybrid, true kernel async for networks, simulated async via thread pool for files/DNS. Understanding this distinction is crucial for building high-performance Node.js applications.