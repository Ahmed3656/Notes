NoSQL cache architecture refers to the design and implementation of in-memory key-value stores used primarily to accelerate read-heavy applications by reducing database load. These systems trade persistence and complex querying for extreme speed and horizontal scalability. The two most prominent examples are Memcached and Redis, each representing a different architectural philosophy.

<hr class="hr-light" />

#### **Core Concepts & Purpose**
The primary goal of a NoSQL cache is to serve frequently accessed data from memory, avoiding slower disk-based databases. It acts as a temporary, high-speed data layer.

 **Key characteristics:**
- **In-Memory Storage:** data resides in RAM for nanosecond to microsecond access times.
- **Key-Value Data Model:** simple access via unique keys.
- **Transience (Volatility):** data may be evicted or lost on restart, unless persistence is configured.
- **Horizontal Scalability:** designed to scale across multiple nodes.
- **TTL (Time-to-Live):** expiration automatically cleans up stale entries.

<hr class="hr-light" />

#### **How it works**
An application first checks the cache for a piece of data using its key. If found (cache hit), it uses that data. If not found (cache miss), it fetches the data from the primary database, stores it in the cache for future requests, and then uses it.

**Caching strategies include:**
- **Cache-Aside (Lazy Loading):** app code manages reading/writing explicitly. Most common.
- **Write-Through:** app writes to both cache and DB simultaneously. Cache stays consistent.
- **Write-Behind:** app writes only to cache, which asynchronously pushes to DB. Faster but risks data loss.
- **More about caching strategies [here](System%20Design.md#Caching)**

---

### **Memcached**
Memcached is a distributed, purely in-memory key-value store designed for ultimate simplicity and raw performance. It's transient by design: no persistence, no replication, just fast caching.

#### **Internal Architecture**

- **Memory Management**
	The key insight is to prevent memory fragmentation. Normal allocation creates scattered gaps too small to use. Memcached solves this with slab allocation:
	- Memory is pre-allocated in 1MB pages.
	- Pages are divided into slab classes by chunk size (e.g., 72B, 96B, 1MB).
	- An item is stored in the smallest chunk that fits it.
	
	This ensures contiguous memory and eliminates fragmentation, but wastes space if items don't fill chunks exactly.
- **LRU Eviction**
	When memory fills, Memcached uses Least Recently Used (LRU) eviction:
	- Each slab class has its own LRU linked list.
	- Accessing an item moves it to the head of its list.
	- A background LRU crawler evicts items from the tail.
	
	Trade-off: simple but adds locking overhead.
- **Threading and Locking**
	- A single listener thread accepts connections on TCP port 11211.
	- For each client, a worker thread handles operations.
	- Originally, Memcached used a global lock, causing bottlenecks.
	- Modern versions use per-item locks —> threads only block when accessing the same key.
	- LRU updates still require synchronization.
- **Read/Write Operations**
	Memcached uses a central hash table with O(1) lookups:
	- Hash the key —> index into the table.
	- Resolve collisions via chaining (linked lists).
	- Reads: hash —> traverse —> return value —> update LRU.
	- Writes: find slab class —> allocate chunk —> store item —> insert into hash table.
- **Distribution**
	Memcached servers are unaware of each other. Distribution happens on the client side:
	- Client libraries (Node.js, Python, etc.) use consistent hashing to map keys to servers.
	- Adding or removing servers requires the client to reshuffle keys, causing cache misses, but keeps servers lightweight.
	- A common challenge is **uneven key distribution** when the hash function or server pool changes, leading to hotspots if not tuned properly.

<hr class="hr-light" />

### **Redis**
Redis is an in-memory key-value store that extends far beyond caching. It supports rich data structures, optional durability, replication, clustering, and pub/sub messaging.

#### **Internal Architecture**
Redis uses a fundamentally different approach than Memcached. At its core:
- **Single-threaded event loop:** all commands execute on one main thread using an event-driven model
- **Hash table + expires table:** primary data stored in a main hash table, with a separate table tracking TTLs
- **Memory allocator:** uses jemalloc by default for efficient memory management without slab classes
- **Background threads:** handle I/O tasks like persistence, replication, and lazy deletion
- **Command processing:** commands are parsed, validated, executed, and results returned in sequence
- **Protocol:** communicates over raw TCP (6379) with RESP (Redis Serialization Protocol). It's binary-safe and faster than HTTP, though less web-friendly. TLS often handled by proxies.

This architecture eliminates locking complexity but means a single slow command can block everything.

#### **Key Features**
- **In-Memory First**
	Like Memcached, Redis keeps all data in RAM for sub-millisecond access. But unlike Memcached, values can be: **Strings, Lists, Sets, Sorted Sets, Hashes, HyperLogLogs (HLL), Streams, etc.**
	This enables complex operations (e.g., appending to a list without fetching/reinserting).
- **Optional Durability**
	Redis supports persistence to survive restarts:
	- **RDB (Snapshotting):** periodic full dumps of the dataset.
	- **AOF (Append-Only File):** logs every write for replay.
	
	Both handled asynchronously by background processes.
	In Docker defaults, persistence is enabled, but in pure-cache mode it's usually disabled for maximum speed.
- **Single-Threaded Core**
	Redis is famously single-threaded for command execution:
	- Avoids locking complexity.
	- Predictable performance.
	- Downside: a CPU-heavy command can block the entire server.
	
	Scaling is achieved with replication and clustering, not threads.
- **Pub/Sub Messaging**
	Redis includes a Publish/Subscribe system:
	- Clients subscribe to channels.
	- Others publish messages.
	- Redis instantly pushes messages to all subscribers.
	
	Works as a lightweight message broker, though not as robust as Kafka or RabbitMQ.
- **Replication & Clustering**
	Redis offers both redundancy and scalability:
	- **Replication:** leader-follower model for read scaling and HA. Followers replicate asynchronously, which means reads may see slightly stale data.  
	- **Clustering:** shards data across 16,384 hash slots. Each slot assigned to a node; failover promotes followers. Consistency during failover is **eventual**, as some writes may be lost in the window before promotion.

<hr class="hr-light" />

#### **Performance Characteristics**
Both systems deliver microsecond-to-millisecond latency, but with different trade-offs:
- **Memcached:** optimized for ultra-fast, small object retrieval, typically tens of microseconds. Best when values are simple and schema-less.
- **Redis:** slightly more overhead due to richer data structures, but still sub-millisecond. Shines when atomic operations or complex data manipulations are needed directly in memory.

#### **When to Use Which**
So, how do you choose? It basically depends on what you need your cache to do.

**You should consider Memcached if:**
- **You need a simple, basic cache.** Your main goal is to make things faster by storing key-value pairs. You don't need complex data types.
- **You need the most speed for simple data.** If you are only caching small strings or blobs, Memcached is built for that specific job and is very efficient.
- **Your data is not critical and can be lost.** Memcached does not save data to disk. If the server restarts, your cache is empty. That's why you use it for data you can easily get again from your main database.
- **You need to scale out easily.** You can just add more Memcached servers. The client handles where to put the keys, so it's easy to make the cache larger.

**You should use Redis if:**
- **You need more than just a basic cache.** Redis is useful for many things. You can use it for caching, but also as a real database or a message broker.
- **You need to use rich data types.** If you need to work with lists, sets, or sorted sets right in the cache, Redis is the right choice. For example, a leaderboard is easy to build with a sorted set.
- **You need persistence.** Redis can save data to disk. This is important if you can't afford to lose all your cached data after a restart.
- **You need built-in replication.** Redis supports master-replica replication out of the box. This is good for high availability, if your main Redis server has a problem, a replica can take over.
- **You need advanced features.** Things like Pub/Sub messaging or atomic counters are built into Redis. If you think you might need these features, Redis is the better option.

**The key insight is this:** Use Memcached for a large, simple, temporary cache. Use Redis when you need a more powerful and flexible in-memory data store.

---

### **How to Implement a Cache Layer**

#### **Memcached Setup**

```bash
docker run --name mem1 -d -p 11211:11211 memcached
```

**In Node.js:**
```javascript
const Memcached = require('memcached');
const cache = new Memcached(['localhost:11211', 'localhost:11212']);
cache.set('key1', 'value1', 3600, (err) => { if (err) console.error(err); });
cache.get('key1', (err, data) => { console.log(data); });
```

**Basic Commands:**
- `telnet localhost 11211` —> Connect to Memcached server via telnet.
- `set <key> <flags> <exptime> <bytes>` —> Store a key-value pair with expiration time.
- `get <key>` —> Retrieve the value for a specific key.
- `delete <key>` —> Remove a key from the cache.
- `flush_all` —> Clear all items from the cache.
- `stats` —> Display general server statistics.
- `stats slabs` —> Show slab class allocation information.
- `stats items` —> Display per-slab class item statistics.
- `version` —> Show the Memcached server version.
- `quit` —> Close the telnet connection.

<hr class="hr-light" />

#### **Redis Setup**

```bash
docker run --name rdb -d -p 6379:6379 redis
docker exec -it rdb redis-cli
```

**In Node.js:**
```javascript
const redis = require('redis');
const client = redis.createClient();

async function getProduct(productId) {
  let product = await client.get(`product:${productId}`);
  if (product) return JSON.parse(product);  // Cache hit
  product = await db.getProduct(productId); // Fallback DB
  if (product) await client.setEx(`product:${productId}`, 3600, JSON.stringify(product));
  return product;
}
```

**Basic Commands:**
- `SET <key> <value>` —> Store a string value for a key.
- `SET <key> <value> EX <seconds>` —> Store with expiration time.
- `GET <key>` —> Retrieve the value for a specific key.
- `DEL <key>` —> Delete one or more keys.
- `EXISTS <key>` —> Check if a key exists (returns 1 or 0).
- `EXPIRE <key> <seconds>` —> Set expiration time for an existing key.
- `TTL <key>` —> Get remaining time-to-live for a key.
- `KEYS <pattern>` —> Find keys matching a pattern (avoid in production).
- `FLUSHALL` —> Remove all keys from all databases.
- `FLUSHDB` —> Remove all keys from current database.
- `INFO` —> Display server information and statistics.
- `PING` —> Test server connectivity (returns PONG).

**Data Structure Commands:**
- `LPUSH <key> <value>` —> Add element to the beginning of a list.
- `RPUSH <key> <value>` —> Add element to the end of a list.
- `LRANGE <key> <start> <stop>` —> Get elements from a list by range.
- `SADD <key> <member>` —> Add member to a set.
- `SMEMBERS <key>` —> Get all members of a set.
- `HSET <key> <field> <value>` —> Set field in a hash.
- `HGET <key> <field>` —> Get field value from a hash.
- `HGETALL <key>` —> Get all fields and values from a hash.

**Pub/Sub Commands:**
- `SUBSCRIBE <channel>` —> Subscribe to a channel (blocks waiting for messages).
- `PUBLISH <channel> <message>` —> Send message to a channel.
- `UNSUBSCRIBE <channel>` —> Unsubscribe from a channel.

**Cluster Commands:**
- `redis-cli --cluster create <node1:port> <node2:port> ... --cluster-replicas <num>` —> Create a new Redis cluster.
- `CLUSTER NODES` —> List all nodes in the cluster with their status.
- `CLUSTER INFO` —> Display cluster state and configuration.
- `CLUSTER SLOTS` —> Show hash slot assignments to nodes.
- `CLUSTER MEET <ip> <port>` —> Add a node to the cluster.
- `CLUSTER FORGET <node-id>` —> Remove a node from the cluster.
- `CLUSTER FAILOVER` —> Manually trigger failover on current node.

---

#### **Pros**
- **Massive performance gains** microsecond latency.
- **Relieves primary database load**.
- **Scales horizontally** by adding nodes.
- **Memcached** —> Ultra-simple, minimal overhead.
- **Redis** —> Versatile: cache, database, and message broker.

<hr class="hr-light" />

#### **Cons**
- **Data volatility:** restart wipes data unless persistence enabled.
- **Cache invalidation challenges:** keeping cache consistent with DB changes is difficult; stale data can be served if not properly managed.
- **Adds complexity:** another layer to deploy/monitor.
- **Memory cost:** RAM is significantly more expensive than disk storage for large datasets.
- **Redis** —> Single-threaded bottlenecks for CPU-heavy ops.
- **Memcached** —> Lacks durability and requires client-side distribution logic.

---

#### **Real-World Use Cases**

- **Memcached**
    - Session storage in large-scale web applications (e.g., PHP or Django apps).
    - Page fragment caching (e.g., rendered HTML blocks).
    - Reducing repetitive database queries for simple, flat objects.
- **Redis**
    - Leaderboards and ranking systems using **Sorted Sets**.
    - Rate limiting and counters with atomic **INCR** operations.
    - Distributed locks for coordination between services.
    - Lightweight message broadcasting with **Pub/Sub**.
    - Caching JSON or complex objects without round trips to reassemble data.