A database cursor is a control structure that enables traversal over the records in a database result set. It provides a way to retrieve, process, and manipulate rows one at a time or in batches, rather than loading the entire multi-gigabyte result set into client memory immediately. Think of it as a pointer or iterator that gives you sequential, controlled access to the output of a `SELECT` query.

<hr class="hr-light" />

#### **Server-Side vs. Client-Side Cursors**
This is the most critical distinction, dictating where the data and state are managed.

- **Client-Side Cursor (Default in most drivers):**
    - **Mechanism:** the entire result set is fetched from the database server, transmitted over the network, and stored in the client application's memory upon `execute()`. the client then iterates through this in-memory set.
    - **Pros:** simple to use. frees up database resources (locks, memory) quickly after the initial fetch.
    - **Cons:** can consume massive client-side RAM and network bandwidth for large results. the client must wait for the entire dataset to be transferred before processing the first row.
- **Server-Side Cursor (Named Cursor):**
    - **Mechanism:** the cursor and the full result set are held on the database server. the client sends `FETCH` commands to retrieve rows in chunks (e.g., `FETCH 100 FROM cursor_name`). only the fetched rows are sent over the wire.
    - **Pros:** enables work with massive datasets that exceed client memory. reduces initial wait time and network load by streaming data in chunks.
    - **Cons:** holds database resources (e.g., locks, transaction ID, a snapshot) open for the cursor's entire lifespan. stateful, making it unsuitable for stateless HTTP requests.

<hr class="hr-light" />

#### **Cursor Sensitivity: What You See When Data Changes**
Cursors can behave differently if the underlying data is modified after the cursor is opened.
- **Insensitive Cursor:** a static snapshot of the result set at the time the cursor was opened. all subsequent `FETCH` operations will return data as it was, ignoring any commits from other transactions. this provides consistency but may show stale data.
- **Sensitive Cursor:** reflects changes made to the underlying data (by yourself or others) as you scroll through the result set. this can lead to non-repeatable reads or phantom reads if the data is modified during iteration.
- **Asensitive Cursor:** the most common default in databases like PostgreSQL. the behavior is implementation-defined; it _may_ see some changes but is not guaranteed to see all of them.

---

#### **How to Use Cursors (PostgreSQL Example)**
Cursors must be used within a transaction. here is a basic example of declaring and using a server-side cursor in PostgreSQL.
```sql
-- Start a transaction
BEGIN;

-- Declare a cursor for a specific query
DECLARE grade_cursor CURSOR FOR 
SELECT student_id FROM grades WHERE grade BETWEEN 90 AND 100;

-- Fetch the first row from the cursor
FETCH grade_cursor;

-- Fetch the next row
FETCH grade_cursor;

-- Fetch the last row (may be inefficient without proper indexes)
FETCH LAST FROM grade_cursor;

-- Close the cursor and end the transaction
COMMIT;
```

<hr class="hr-light" />

#### **When to Use Cursors**
Cursors are a specialized tool for specific, data-intensive operations. they are not a general-purpose replacement for `LIMIT`/`OFFSET`.

**Primary use cases:**
- **Batch processing & ETL jobs:** migrating or transforming billions of rows by chunking them into manageable batches to avoid overwhelming application memory —> `FETCH 1000`, process, repeat.
- **Data streaming:** feeding data from the database to a downstream consumer (e.g., a file, API response, or message queue) in a continuous, memory-efficient stream.
- **Stored procedures:** using imperative logic inside the database (PL/SQL) to loop through query results row-by-row for complex validation or calculations.
- **Handling very large result sets:** when there is truly no alternative to processing a result set that is too large to fit in RAM.

<hr class="hr-light" />

#### **Common Pitfalls & Best Practices**

**Common pitfalls:**
- **Using for web pagination:** a classic anti-pattern. server-side cursors are stateful and tied to a single database connection, which is incompatible with stateless, scalable web servers that use connection pools.
- **Leaking resources:** failing to `CLOSE` a cursor or `COMMIT`/`ROLLBACK` a transaction will leave resources locked on the database server, leading to performance degradation and eventual failure.
- **Ignoring transaction lifespan:** long-running cursor transactions prevent `VACUUM` from cleaning up dead tuples, can block schema changes (`DDL`), and increase the risk of transaction ID wraparound.
- **Network chatter:** fetching too few rows per `FETCH` operation (e.g., 1 row at a time) can result in terrible performance due to the high number of network round-trips.

**Best practices:**
- **Prefer keyset pagination over `OFFSET`:** for pagination, use a `WHERE` clause like `WHERE id > <last_seen_id>` instead of `LIMIT n OFFSET n*page`. it's faster and doesn't break if new data is inserted.
- **Choose the right chunk size:** when using a server-side cursor, experiment with the `fetchmany(size)` value (e.g., 1000 rows) to find the optimal balance between memory usage and network round-trips.
- **Always use a context manager:** in code, use `with conn.cursor() as cur:` to ensure the cursor and connection are properly closed, even if an error occurs.
- **Monitor open cursors:** use system views like `pg_cursors` in PostgreSQL to monitor for and identify cursors that have been left open unintentionally.

---

#### **Pros and Cons**

**Pros:**
- **Reduces client memory pressure:** the client doesn't need to hold gigabytes of data in RAM, only the current batch.
- **Enables streaming:** allows for efficient, incremental processing and streaming of large datasets.
- **Can be canceled:** a long-running query using a cursor can be canceled partway through, and the transaction can be rolled back, freeing up resources.

**Cons:**
- **Stateful & not scalable:** the cursor exists within a specific database transaction on a specific server connection. this makes it **impossible to use in a stateless, horizontally scaled web application** where requests are load-balanced to different backend servers.
- **Increases server memory pressure:** the server must allocate resources to maintain the cursor's state and the transaction for its entire duration.
- **Long-running transactions:** cursors hold transactions open, which can block crucial maintenance operations like `VACUUM`, `ALTER TABLE`, or the acquisition of exclusive locks.
- **Network overhead (server-side):** while it saves total bandwidth, fetching small batches repeatedly can be slower than one big fetch due to the latency of many network round-trips.