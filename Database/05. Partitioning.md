#### **Partitioning**
The practice of logically splitting a single large table into smaller, more manageable physical segments (partitions) while presenting them as one table to the application. The core idea is to minimize the amount of data that must be scanned for any given query by eliminating entire partitions from the search early.

<hr class="hr-light" />

#### **Horizontal vs. Vertical Partitioning**
- **Horizontal Partitioning:** splits a table by rows. Each partition has the same schema but contains a different subset of the total rows. This is the most common form of partitioning.
    - Example: a `customers` table partitioned by `id` range: `customers_1m` (ids 1-1,000,000), `customers_2m` (ids 1,000,001-2,000,000).       
- **Vertical Partitioning:** splits a table by columns. Less frequently accessed or large columns (like BLOBs or JSON documents) are moved to a separate table, linked by the primary key.
    - Example: moving the `profile_picture` column from a `users` table into a separate `users_profile_pictures` table to speed up queries that don't need the image.

<hr class="hr-light" />

#### **Partitioning Types**
- **By Range:** partitions are defined by ranges of values from the partition key (e.g., `date`, `id`).
    - **Use Case:** time-series data (e.g., `log_date BETWEEN '2024-01-01' AND '2024-01-31'`), sequential IDs.
- **By List:** partitions are defined by a discrete list of values (e.g., `country_code`, `status`).
    - **Use Case:** geographically distributed data (e.g., `region IN ('US', 'CA', 'MX')`), enumerable states.
- **By Hash:** a hash function is applied to the partition key to determine which partition a row belongs to. This aims to distribute data evenly.
    - **Use Case:** when you need an even distribution of data and range-based queries are not necessary.

<hr class="hr-light" />

#### **How to Partition a Table**
- **Create the Master Partitioned Table:** we have to first create a **Master Partitioned Table**, this table defines the structure but will remain empty. `PARTITION BY RANGE` clause is the key, specifying the column that will determine how data is split.
	```sql
	CREATE TABLE master_partitioned (
	    col_a dataType,
	    col_b dataType,
	    ...
	) PARTITION BY RANGE (col_{x}); -- the partition key
	```

- **Create Child Partitions:** next, we create the actual physical tables (the partitions) that will hold the data. Each one defines a specific range of values for the partition key.
	```sql
	CREATE TABLE partition1 PARTITION OF master_partitioned
	    FOR VALUES FROM (val_0) TO (val_1);
	
	CREATE TABLE partition2 PARTITION OF master_partitioned
	    FOR VALUES FROM (val_1) TO (val_2);
	
	CREATE TABLE partition3 PARTITION OF master_partitioned
	    FOR VALUES FROM (val_2) TO (val_3);
	
	CREATE TABLE partition4 PARTITION OF master_partitioned
	    FOR VALUES FROM (val_3) TO (val_4);
	```
	
	**Notes**
	- We don't have to specify the column we are partitioning on as the database is aware of which column we are partitioning on since we defined it in the `master_partitioned` table.
	- The range of the partition is [val_a, val_b) (from val_a inclusive to val_b exclusive).

- **Insert Data into the Partitioned Table:** you insert data into the master table (`master_partitioned`), **not** the child tables directly. The database automatically routes each row to the correct partition based on the value of the partition key (`col_{x}`)
	```sql
	-- The DB decides where each row goes based on the value of 'col_{x}'
	INSERT INTO master_partitioned (col_a, col_b, ...)
	SELECT * FROM original_table;
	```

- **Verify the Data Distribution:** after insertion, you can verify that the data is correctly distributed by querying the individual partitions.
	```sql
	-- Check row count in the first partition
	SELECT COUNT(*) FROM partition1;
	
	-- Check the max value in a partition to confirm data integrity
	SELECT MAX(col_{x}) FROM partitionX;
	```

- **Create Indexes on the Partitioned Table:** a powerful feature of modern databases is the ability to create an index on the master table, which automatically creates identical indexes on every underlying partition.
	```sql
	-- Create one index on the master table
	CREATE INDEX idx_name ON master_partitioned (col_{x});
	```
	
	The database creates individual indexes named `col_{x}_parts_index` on each child table (`partition1`, `partition2`, etc.). You do not need to manage indexes for each partition manually.

- **Important Notes**
	- The application and your queries only interact with the master table. The database handles the complexity of which partition to read from or write to. This provides a clean abstraction while delivering the performance benefit of **partition pruning**, the query planner automatically excludes irrelevant partitions from the scan based on the `WHERE` clause.
	- After migrating the data successfully we can drop the original table and just rely on the partitioned table.

<hr class="hr-light" />

#### **How to Automate Partitioning**
For large tables (e.g., 1 billion rows), manually creating hundreds of partitions is impractical. The process can be automated using a client-side script (e.g., Node.js) to dynamically generate and attach partitions.

**Steps to Automate:**
1.  **Connect to the PostgreSQL instance** and create the target database.
2.  **Create the master partitioned table** (this remains empty).
3.  **Calculate partition ranges** based on desired partition size (e.g., 10 million rows per partition).
4.  **Loop through each range**, dynamically generating SQL to:
    - Create a child table with the same structure as the master.
    - Attach the child table to the master, defining its value range.

**Example Automation Script (Node.js with `pg` library):**
```javascript
// create_partitions.js
const { Client } = require('pg');

async function createPartitions() {
  // 1. Connect to PostgreSQL
  const rootClient = new Client({
    host: 'localhost',
    port: 5432,
    user: 'postgres',
    password: 'password',
    database: 'postgres'
  });
  await rootClient.connect();

  // 2. Create the target database (DROPS IF EXISTS)
  // await rootClient.query('DROP DATABASE IF EXISTS customers;');
  await rootClient.query('CREATE DATABASE customers;');
  await rootClient.end();

  // 3. Connect to the new database
  const client = new Client({
    host: 'localhost',
    port: 5432,
    user: 'postgres',
    password: 'password',
    database: 'customers'
  });
  await client.connect();

  // 4. Create the master partitioned table
  await client.query(`
    CREATE TABLE customers (
      id INT NOT NULL,
      name VARCHAR(100)
    ) PARTITION BY RANGE (id);
  `);

  // 5. Automatically generate and attach partitions
  const totalRows = 1000000000; // 1 billion
  const partitionSize = 10000000; // 10 million per partition
  const numPartitions = totalRows / partitionSize; // 100 partitions

  for (let i = 0; i < numPartitions; i++) {
    const fromId = i * partitionSize;
    const toId = (i + 1) * partitionSize;

    const partitionName = `customers_${fromId}_${toId}`;

    // 5a. Create child table with same structure
    const createTableQuery = `
      CREATE TABLE ${partitionName} (LIKE customers INCLUDING ALL);
    `;
    await client.query(createTableQuery);

    // 5b. Attach child table to master with range
    // NOTE: Range is [fromId, toId) (inclusive, exclusive)
    const attachPartitionQuery = `
      ALTER TABLE customers ATTACH PARTITION ${partitionName}
      FOR VALUES FROM (${fromId}) TO (${toId});
    `;
    await client.query(attachPartitionQuery);
    console.log(`Created partition: ${partitionName}`);
  }

  await client.end();
}

createPartitions().catch(console.error);
```

**Populating the Partitioned Table:**
After automation, insert data into the master table. The database routes rows based on the partition key (`id`).
```javascript
// populate_customers.js
const { Client } = require('pg');
const client = new Client({ /* ... same config as above ... */ });

async function populate() {
  await client.connect();
  // Insert into master table - DB routes to correct partition
  await client.query(`
    INSERT INTO customers (id, name)
    SELECT generate_series, 'Customer_' || generate_series
    FROM generate_series(1, 1000000000);
  `);
  await client.end();
}

populate().catch(console.error);
```

<hr class="hr-light" />

#### **When to Use Partitioning**
Partitioning is a powerful but complex tool. Use it strategically, not by default.

**Use Partitioning When:**
- Your table has hundreds of millions to billions of rows.
- Your most common queries filter by a single column (e.g., `date`, `customer_id`, `region`).
- You need efficient data lifecycle management (e.g., archiving old data via `DROP PARTITION`).
- You require hot/cold data separation (e.g., recent data on SSD, old data on HDD).

**Avoid Partitioning When:**
- Your entire table fits in RAM (partitioning overhead may hurt performance).
- Queries do not filter by the partition key (prevents pruning, makes queries slower).
- You have fewer than ~10 million rows (complexity outweighs benefits).

| Scenario                          | Best Approach                                     |
| --------------------------------- | ------------------------------------------------- |
| Time-series data (logs, metrics)  | **Range partitioning** on `date`/`timestamp`      |
| Even data distribution (user IDs) | **Hash partitioning**                             |
| Geo-based or categorical data     | **List partitioning** (e.g., `country`, `status`) |
| Fast deletion of old data         | **Detach/DROP PARTITION**                         |
| Hot data on SSD, cold on HDD      | **Tablespace assignment** per partition           |

<hr class="hr-light" />

#### **Partition Pruning**
Partition pruning is the optimizer’s ability to skip irrelevant partitions during a query. It only works if the `WHERE` clause allows the database to identify specific partitions.

**Good Query (Enables Pruning):**
```sql
-- Scans ONLY the 'sales_2025_01' partition
SELECT * FROM sales 
WHERE sale_date BETWEEN '2025-01-01' AND '2025-01-31';
```

**Bad Query (Disables Pruning):**
```sql
-- Scans ALL partitions (slow!)
SELECT * FROM sales 
WHERE EXTRACT(MONTH FROM sale_date) = 1;
```

**Tip:** Always use direct, sargable conditions (e.g., `=`, `BETWEEN`, `IN`) on the partition key.

---

#### **Pros**
- **Query Performance:** dramatically improves queries by enabling **partition pruning**. The database can instantly eliminate entire chunks of data (partitions) from the scan. This is a massive win when you are **I/O or memory-bound** (e.g., tables too large for RAM), as it forces the database to read only small, relevant pieces from disk instead of the entire massive table.
- **Easier Planner Decisions:** makes the query planner's job easier. Working on a smaller partition simplifies the choice between a **sequential scan** (fast on a small partition) and a **scattered index scan** (which can be slower on a huge table if it has to jump around too much).
- **Easy Bulk Loading & Archiving:** you can load massive amounts of data into a standalone table and then instantly **ATTACH** it to the partitioned table as a new partition. This is also perfect for archiving: old, barely-accessed partitions can be **DETACHED** and moved to cheap, slow storage (e.g., an old HDD) while keeping active data on fast SSDs.
	- **MySQL/MariaDB CSV Trick:** a powerful bulk-loading trick in MySQL is using the **CSV storage engine**. You can point a table directly at a CSV file on disk (e.g., 300 million rows) and it instantly becomes a queryable table. You can then attach this table as a partition, making data ingestion extremely efficient. (This specific feature is not available in PostgreSQL).

<hr class="hr-light" />

#### **Cons**
- **Update Overhead (Row Movement):** this is the biggest downside. If an update changes the value of the partition key (e.g., changing a `grade` from 34 to 36), the database must perform a **slow `DELETE` from the old partition and an `INSERT` into the new one**. This is expensive I/O and can cause significant wear on SSDs if done frequently.
- **Inefficient Queries Can Be Worse:** if a query's `WHERE` clause doesn't allow for partition pruning (e.g., `WHERE id > 1`), the database must scan **every single partition**. This can result in performance that is **slower than if you had just one big table** because it now has to open and read from multiple tables instead of one.
- **Schema Changes Can Be Tricky:** while modern DBMSs can propagate changes like adding an index from the parent table to all children, this isn't always seamless. Some operations may not be fully supported across all partition types, adding complexity to maintenance.

<hr class="hr-light" />

**The Bottom Line:** Partitioning is a powerful tool for managing large datasets, but it's a double-edged sword. Its benefits are massive for specific use cases (time-series data, archiving) but it introduces new overhead and requires careful planning to avoid making performance worse.

---

#### **Notes**
- **YOU MUST ENABLE `enable_partition_pruning`.** This is the feature that makes partitioning work by allowing the planner to skip irrelevant partitions. If this is **OFF**, your database will scan **every single partition**, making your query slower than having no partitions at all. **ALWAYS VERIFY THIS IS ON.**
	- **Check by running:** `SHOW enable_partition_pruning;`
	- **Turn it on by running:** `SET enable_partition_pruning = on;`
- **Don't partition small tables.** If your entire table fits in RAM, a full table scan is already fast. Partitioning's main job is to avoid reading the whole table from disk. If the table is already in memory, you're just adding complexity for no real speed gain. The planner overhead might even make it slower.
    - **How to check if a table is small (fits in RAM):**
        - **Find the table's OID:** `SELECT oid FROM pg_class WHERE relname = 'your_table_name';`
        - **Check its size in bytes:** `SELECT pg_relation_size(oid) FROM pg_class WHERE relname = 'your_table_name';`
        - **Get a human-readable size:** `SELECT pg_size_pretty(pg_relation_size(oid)) FROM pg_class WHERE relname = 'your_table_name';`
        - **One-liner for size:** `SELECT pg_size_pretty(pg_total_relation_size('your_table_name'));`
- **Indexing Best Practices for Partitions:**
	- **Index the Partition Key:** always create an index on the partition key column(s) for faster pruning.
	- **Local Indexes:** use if queries mostly filter within a single partition.
	- **Global Indexes (PostgreSQL 12+):** use for cross-partition queries or unique constraints across all partitions.
	- **Create on Master:** Use `CREATE INDEX ON master_table (column);` to auto-create indexes on all partitions.
- **Avoid Too Many Partitions:** performance degrades as the number grows due to planner overhead.
	- **Less Than 100 Partitions:** ideal range.
	- **100 – 1,000 Partitions:** monitor planner performance.
	- **Greater Than 1,000 Partitions:** avoid unless necessary (e.g., time-series with daily partitions).