
#### **The Different Types of Scans**
- **Table Scan:** reads the entire table page-by-page, from beginning to end, inspecting every row to see if it matches the query criteria. Used when a large percentage of the table is needed, the table is very small, or when there are no applicable indexes.
	- Pros: simple and always works. Excellent for sequential I/O efficiency when most data is needed.
	- Cons: highly inefficient if only a few rows are needed from a large table, as it reads everything.
	- Best For: queries that need a large percentage of the table (>20%), very small tables, or when no indexes exist.
- **Index Scan:** uses a B-Tree or similar index to perform binary search to find the exact location of specific rows. After finding the entries, it performs individual random I/O operations to fetch each row from the heap. Used when fetching a very small/specific number of rows or for queries that return a low percentage of the total table rows.
	- Pros: extremely fast (O(log n) lookup) for finding a small number of specific rows (point queries).
	- Cons: performance plummets when fetching many rows due to the overhead of many random I/O operations.
	- Best For: queries that return a very small, specific set of rows (e.g., <1-5% of the table) and highly selective conditions (e.g., `WHERE id = 123`).
- **Index Only Scan:** uses the index **without touching the heap** (table data pages) because all required columns are stored in the index. If the query only requests columns included in the index, Postgres can return results directly from the index.
	- Pros: faster than a regular index scan since it avoids fetching rows from the heap and does less I/O as only the index pages are read.
	- Cons: works only when the index contains all requested columns and requires that the visibility map bits are set, otherwise databases still need to check the heap to ensure rows are visible.
	- Best For: point lookups or queries requesting only indexed columns and situations where you want maximum performance on very frequent reads.
	- Use Case: enabled by covering indexes (e.g., `CREATE INDEX idx_cover ON table (key_col) INCLUDE (other_col)`). Ideal for queries that select only indexed columns.
- **Bitmap Index Scan:** uses the index to find all matching row locations, builds an **in-memory bitmap** marking relevant heap pages, sorts them by page address, and then fetches all needed rows sequentially. This is the "Sweet Spot" query, it is used when an index scan would be too slow (too many random I/Os) but a table scan would read too much unnecessary data (e.g., `WHERE category_id = 5`, which return ~10% of rows).
	- Pros: combines the filtering of an index with the I/O efficiency of a sequential scan. Perfect for medium-size result sets.
	- Cons: adds memory overhead to build and sort the bitmap. Not ideal for extremely large or extremely small result sets.
	- Best For: medium-selectivity queries (e.g., returning 5-20% of rows) and complex multi-condition filters.
	- Key Advantage: can perform bitwise operations (AND, OR) on multiple bitmaps from different indexes to efficiently resolve complex `WHERE` clauses (e.g., `category_id = 5 AND status = 'active'`).

<hr class="hr-light" />

#### **Key Indexing vs. Non-Key Indexing**
- **Key Indexing:** a column (or set of columns) explicitly defined as the search key of the index. This key determines the order of the index entries and is used for searching, sorting, and filtering.
	- Usage: essential for efficiently answering queries with `WHERE`, `ORDER BY`, `GROUP BY`, or `JOIN` clauses that reference the key column(s).
	- Example: `CREATE INDEX ON employees (department_id)` allows fast lookup of all employees in a specific department.
- **Non-Key (Included) Indexing:** additional columns added to an index solely at the leaf level, not as part of the search key. These columns are stored in the index but do not affect the index’s order or structure.
	- Purpose: to cover a query entirely by the index, eliminating the need to access the heap (table) altogether. This is called a **covering index**.
	- Example: `CREATE INDEX ON employees (department_is) INCLUDE (salary)` allows the database to return both `department_id` and `salary` directly from the index without fetching the full row from the heap.
<br/>
- **Creating an Index with Included Columns for Efficiency:**
    - Scenario: a frequent query filters on one column but requires data from another (e.g., `SELECT employee_id, salary FROM employees WHERE department_id = 5`).
    - Inefficient Approach: an index on just `(department_id)` would quickly find the rows but require a **heap lookup** for each row to retrieve `salary`, resulting in random I/O.
    - Efficient Approach: an index on `(department_id) INCLUDE (salary)` stores the `salary` values directly in the leaf pages of the index. The query can be answered **entirely from the index**, avoiding heap accesses and reducing I/O to a single index scan.
    - Benefit: dramatically improves performance for specific queries by making the index **self-sufficient**, trading slightly larger index size for significantly faster read operations.

<hr class="hr-light" />

#### **Clustered vs. Nonclustered Indexes**
- **Clustered Index:** a clustered index fundamentally _is_ the table, physically reorganized into a sorted B-tree structure where the leaf nodes are the actual data pages. This means the data rows themselves are stored on disk in the exact order of the index key, allowing for highly efficient range scans and ordered retrievals. Consequently, there can only be one clustered index per table, as the data can only be physically sorted in one sequence, and it dictates the reference pointer (its key) that all nonclustered indexes will use.
    - **Usage:** ideal for range queries and operations requiring sorted data retrieval. Defines the logical order of the table.
    - **Example:** a clustered index on `employees(employee_id)` stores all table rows sorted by `employee_id`.
- **Nonclustered Index:** a nonclustered index is a separate, independent B-tree structure that exists alongside the table data. Its leaf nodes do not contain the actual data rows but instead hold the index key values along with a pointer, either a Row ID (RID) for heaps or the clustered index key for indexed tables, back to the full row in the main table. This allows for fast seeking on different columns but often requires a costly lookup operation to retrieve the complete row, making covering indexes (which include all needed columns) a critical performance optimization.
    - **Usage:** optimizes queries filtering on non-clustered columns. Requires a **lookup** to fetch the full row from the clustered index or heap.
    - **Example:** a nonclustered index on `employees(department_id)` allows fast searches by department, but each result requires a lookup to get the full employee data.
- **Key Difference:**  
    The clustered index is the table, physically ordered. A nonclustered index is a copy of data with a pointer to the full row, requiring extra steps to retrieve complete records.
    **The Fundamental Trade-off:** this structure allows for multiple sorted access paths (via nonclustered indexes) **without the massive storage and write overhead of duplicating the entire table** for each sort order.

**Database-Specific Notes:**
- **SQL Server:** explicit `CLUSTERED`/`NONCLUSTERED` keywords. Heaps use RIDs; clustered tables use key lookups.
- **MySQL (InnoDB):** clustered index = Primary Key. Secondary indexes point to the PK.
- **PostgreSQL:** no true clustered index; `CLUSTER` command reorders physically but doesn’t maintain it. Indexes point to heap TIDs.

<hr class="hr-light" />

#### **Composite Indexes & The Leftmost Prefix Rule**

- **How They Work:** a composite index on `(column_a, column_b)` is sorted hierarchically: first by `column_a`, and then _within each group of identical `column_a` values_ by `column_b`. this structure enables highly efficient seeks for queries filtering on the leftmost columns.
- **The Rule:** the index can be used for queries that filter on:
    - `column_a` (uses the full sorted order of the first column)
    - `column_a AND column_b` (uses both sorting levels for a precise seek)
    <br/>
	It **cannot** be used for efficient seeks on:
    - `column_b` alone (the values are scattered without the leading `column_a` group).
- **Key Insight:** the order of columns in the index is critical. Place the most frequently filtered or highest-selectivity column first to enable the broadest range of efficient queries.
- **Exception (Index-Only Scan):** a query selecting _only_ `column_b` might still scan the entire index (which is smaller than the table) but this is a slow scan, not a fast seek.
- **Example:** 

  | id  | lname     | fname   | age | city           |
  |----|-----------|---------|------|------------|
  | 7   | Brown     | Eve      | 38    | Miami       |
  | 8   | Davis      | Frank    | 33   | Phoenix    |
  | 4   | Jones      | Alice    | 27    | Austin      |
  | 5   | Jones      | David   | 31    | Chicago   |
  | 1   | Smith      | Alice     | 29   | Seattle     |
  | 2   | Smith      | Bob      | 35   | Portland   |
  | 3   | Smith      | Charlie  | 41  | Denver     |
  | 10 | Taylor      | Henry   | 45  | Dallas       |
  | 9   | Wilson    | Grace    | 29  | Atlanta     |
  | 6   | Williams | Bob       | 24  | Boston      |

**Composite Index: `idx_name` on `(lname, fname)`**

- Index Used (Efficient Seek):
	- `WHERE lname = 'Smith'` → Jumps to "Smith" section (sorted order).
	- `WHERE lname = 'Jones' AND fname = 'Alice'` → Finds "Jones", then seeks "Alice" within Jones group.
	- `WHERE lname IN ('Smith', 'Jones')` → Scans multiple but sorted groups efficiently.

- Index NOT Used Efficiently:
	- `WHERE fname = 'Alice'` → "Alice" appears randomly (e.g., under Jones, Smith, etc.). No sorted order for `fname` alone → requires full index scan.
	- `WHERE fname = 'Bob' AND lname = 'Smith'` → Uses index (leftmost prefix `lname` is used first, then `fname` is sorted within `Smith`).
	- `WHERE city = 'Denver'` → Column not in index → ignores index.

**Key Reason:**  
Without `lname`, the `fname` values are **scattered randomly** across the index.  
Example: "Alice" appears at
- `(Jones, Alice)`
- `(Smith, Alice)`
- ...etc.
No way to binary-search for "Alice" directly → must scan entire index → inefficient.

<hr class="hr-light" />

#### **How the Database Optimizer Chooses Indexes**
- **Cost-Based Decision Making:** the optimizer doesn't guess it calculates. It generates multiple execution plans (e.g., sequential scan, single-index scan, multi-index bitmap scan) and estimates the cost (I/O, CPU, memory) for each based on internal statistics.
- **Statistics Are Critical:** databases maintain detailed statistics (e.g., `pg_statistics` in PostgreSQL) about:
    - Number of rows and pages in a table.
    - Distinct values and value distribution (histograms) in columns.
    - Correlation between columns.  
    
	**These stats help estimate selectivity (e.g., `WHERE country = 'US'` might match 5% of rows).**
- **Multi-Index Strategies:**
    - **Bitmap Index Scan:** for conditions like `WHERE a = 1 AND b = 2`, the optimizer can use two indexes, one for `a` and one for `b`, build bitmaps of matching row locations, and combine them (using bitwise `AND`/`OR`) before fetching rows from the heap. This is efficient for medium-selectivity queries.
    - **Single Index + Filter:** if one index (e.g., on `a`) is highly selective (returns few rows), the optimizer may use only that index, fetch the rows, and then filter them in memory for the second condition (e.g., `b = 2`). This avoids the overhead of using two indexes.
- **When Indexes Are Ignored:** if statistics indicate a condition matches a large portion of the table (e.g., >20-30%), a **parallel sequential scan** is often faster than any index access. This is especially true for outdated statistics or poorly selective indexes (e.g., an index on a column with only 3 distinct values).
- **Dangers of Outdated Statistics:** if you bulk-insert millions of rows without updating statistics (via `ANALYZE` in PostgreSQL), the optimizer may still think the table is small and choose a catastrophic plan (e.g., full scan on a 100M row table). Always update stats after large data changes.
- **Manual Overrides (Hints):** in rare cases, you can force index usage with database-specific hints (e.g., `/*+ Index(...) */` in Oracle), but this is risky and should only be used when you know the optimizer’s choice is wrong due to unique workload knowledge.
- **Key Insight:** the optimizer always picks the plan with the lowest estimated cost. Understanding selectivity, statistics, and index types (B-tree, hash, etc.) helps you design better indexes and write queries that leverage them effectively. Use `EXPLAIN ANALYZE` to validate plans.

<hr class="hr-light" />

#### **Bloom Filters**
- **What They Solve:** Bloom filters provide an extremely memory-efficient way to check if an element **definitely is not** in a set, avoiding expensive lookups (e.g., database queries) for non-existent items. They trade absolute accuracy for minimal memory usage and speed.
- **How They Work:**
    - A Bloom filter is a fixed-size **bit array** (e.g., 64 bits, 1024 bits) and uses **multiple hash functions**.
    - To add an element (e.g., `username = "Jack"`), hash it with each function, compute the modulo with the array size, and set the bits at those positions.
    - To check for an element, hash it and check if all corresponding bits are set. If any bit is `0`, the element is **definitely not** in the set. If all are `1`, the element **may be** in the set (with a chance of false positives).
- **Key Properties:**
    - **No False Negatives:** if an element was added, the filter will always report it as present.
    - **False Positives Possible:** different elements may hash to the same bits, so a "maybe" result requires a definitive check (e.g., querying the database).
    - **Inexpensive:** very low memory footprint and O(1) time complexity for inserts and checks.
- **The Hash Function Trade-Off:**
    - **Single Hash Function:** fills the bitmap slowly but has a **very high false positive rate** due to frequent collisions.
    - **Multiple Hash Functions:** **dramatically reduces false positives** (a collision must occur on _all_ bits), but fills the bitmap much faster, leading to saturation.
    - **Design Goal:** the number of hash functions and bitmap size are chosen to achieve a target false positive rate (e.g., 1%) for an expected number of elements.
- **Optimal Parameters Calculation:**
    - Let `n` be the number of elements to insert, `m` the size of the bit array, and `k` the number of hash functions.
    - The optimal number of hash functions `k` that minimizes the false positive probability `p` is: $k = \frac{m}{n} \ln(2)$
    - The required bitmap size `m` for a desired false positive rate `p` is: $m = -\frac{n \ln(p)}{(\ln(2))^2}$
- **Hash Function Selection:**
    - Goal is **independent, uniformly distributed** outputs. Collisions are expected; the filter relies on requiring collisions across _all_ `k` functions for a false positive.
    - **Implementation:** often simulated using a **single high-quality hash function** (e.g., MurmurHash, xxHash) with `k` different seeds (e.g., `hash_i(value) = murmurhash(value, seed_i) % m`).
- **Counting Bloom Filters:**
    - **Purpose:** extends the standard Bloom filter to support **deletion** by replacing each bit with a small counter (e.g., 4 bits).
    - **Mechanism:** insertion increments counters, deletion decrements them. An element is considered present if all its counters are > 0.
    - **Trade-off:** supports deletion at the cost of **significantly increased memory overhead** (typically 4x the storage) and a small risk of counter overflow.
- **Use Cases:**
    - Avoiding unnecessary database queries for non-existent keys (e.g., username availability checks).
    - Network routers and distributed systems (e.g., Apache Cassandra, Redis) use them to reduce expensive operations.
- **Limitations:**
    - **Cannot Remove Items:** standard Bloom filters do not support deletion (though variants like Counting Bloom filters do).
    - **Saturation:** as more items are added, the false positive rate increases. Once all bits are set, every check returns "maybe," rendering the filter useless.
- **Design Trade-off:** the false positive rate can be reduced by using a larger bit array or more hash functions, at the cost of increased memory and computation.

---

#### **Notes**
- We can force an **Index Scan** instead of a **Bitmap Scan** by using `LIMIT` for very small result sets (e.g., < 10 rows) to minimize startup cost and avoid bitmap overhead. This is effective when retrieving a tiny fraction of the table (e.g., 0.01%). However, if the number of matching rows is larger (e.g., > 1% of the table), a **Bitmap Heap Scan** becomes far more efficient. It replaces many random I/O operations with sequential I/O by reading sorted heap pages, making it ideal for medium-sized result sets.
	- **Caution:** forcing an Index Scan with `LIMIT` requires setting a safe upper bound (e.g., `LIMIT 100`) to prevent silent data truncation. Use only when certain of the maximum result size.
	- In most cases, **trust the planner**. It uses precise statistics to choose the optimal scan type. Use `EXPLAIN ANALYZE` to validate plans before forcing a specific scan method.
- **Creating an index blocks all write operations until it is done as it requires an exclusive lock on the table.** Use `CREATE INDEX CONCURRENTLY name ON table (column)` to allow writes to continue during index creation, essential for production databases.
	- **How it works:** the operation performs multiple table scans to build the index while tracking changes from concurrent writes. New data inserted during the process is included in the final index, ensuring consistency.
    - **Trade-offs:** concurrent indexing takes longer, uses more CPU/memory, and may fail due to conflicts (e.g., uniqueness violations), leaving an invalid index that must be dropped and recreated.
    - **Best Practice:** always use `CONCURRENTLY` for large tables in live environments. Verify success with `\d table_name` and monitor for invalid indexes.
- **Avoid using random UUIDs (v4) as indexed keys** due to their severe performance impact on B-tree structures. Their randomness causes frequent page splits, high I/O overhead, buffer pool thrashing, and index fragmentation, drastically slowing writes and reducing read efficiency for range scans. Instead, prefer **ordered identifiers** (e.g., auto-increment integers, UUIDv7, or ULIDs) which append sequentially and minimize splits. Reserve random UUIDs only for use cases requiring unpredictability, such as security tokens, and avoid indexing them unless absolutely necessary.
- **Long-running update transactions that roll back create significant performance overhead** due to PostgreSQL's multi-version concurrency control (MVCC). Updates create new row versions, requiring index updates and generating dead tuples. On rollback, these become invalid but are not cleaned up immediately, instead, PostgreSQL relies on the `VACUUM` process to lazily reclaim space. This leads to:
	- **Increased I/O:** pages cluttered with dead tuples force more disk reads for fewer live rows.
	- **CPU Overhead:** transaction visibility checks must filter out dead rows during queries.
	- **Table Bloat:** delayed cleanup wastes storage and degrades query performance over time.
	
		PostgreSQL prioritizes **availability** (lazy cleanup), while other databases may use **eager rollback** (via undo logs) that blocks restart until recovery, a trade-off between immediate consistency and operational continuity.