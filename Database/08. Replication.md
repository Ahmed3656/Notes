The practice of maintaining multiple copies of the same data across different database servers. The core idea is to enhance data availability, improve read performance, and provide fault tolerance by creating one or more synchronized replicas from a primary source.

<hr class="hr-light" />

#### **Master-Backup vs. Multi-Master Replication**
- **Master-Backup Replication (Primary-Secondary):** a replication model where **one master/leader node** accepts all write operations (INSERTs, UPDATEs, DELETEs, DDLs). One or more **backup/standby/follower nodes** receive a stream of these changes from the master and apply them to their own datasets.
    - **Pros:** simple to implement. no write conflicts to resolve.
    - **Cons:** the master is a single point of failure for writes. read scalability is limited to the number of read replicas.
- **Multi-Master Replication:** a replication model where **multiple master/leader nodes** can independently accept write operations. These masters then work to synchronize their changes with each other and with any follower nodes.
    - **Pros:** no single point of failure for writes. can write to the local master in a geographically distributed setup.
    - **Cons:** extremely complex to implement. requires a mechanism to **resolve conflicts** when the same data is changed on two different masters simultaneously.

<hr class="hr-light" />

#### **Replication Types: Physical vs. Logical**
- **Physical Replication (WAL Shipping):** the replica receives an exact byte-for-byte copy of the primary's Write-Ahead Log (WAL) and applies the same physical changes to its data files. The standby is essentially a block-level clone of the primary.
  - **Pros:** very efficient, guaranteed consistency.
  - **Cons:** replica must be same version/architecture, cannot replicate subset of tables.

- **Logical Replication (Change Data Capture):** the primary decodes its WAL into logical row changes (individual `INSERT`, `UPDATE`, `DELETE` statements) and streams these operations to replicas. Each replica applies the changes using its own execution engine.
  - **Pros:** can replicate specific tables only, cross-version, enables zero-downtime upgrades.
  - **Cons:** higher overhead, potential for conflicts.

**Architectural Impact:** this fundamental difference explains why companies like Uber moved from PostgreSQL's physical replication to MySQL-based solutions with better logical replication support for their microservices architecture.

<hr class="hr-light" />

#### **Synchronous vs. Asynchronous Replication**
- **Synchronous Replication:** a write transaction to the master is **blocked and not confirmed** to the client until it has been successfully written to one or more backup nodes.
    - **Configurations:** can be tuned for durability (e.g., wait for 2 replicas, wait for 1 replica, wait for any replica to acknowledge).
    - **Pros:** guarantees strong consistency; the data is identical on the master and replicas at the time of commit. zero data loss if the master fails.
    - **Cons:** significantly **increases write latency** as the transaction waits for network round-trips. if a replica goes down, writes to the master can also fail or hang.
- **Asynchronous Replication:** a write transaction is **considered successful** as soon as it is written to the master. The changes are then propagated to the replica nodes **afterwards**, in a background process.
    - **Pros:** very low impact on write latency, as the client does not wait for the replicas. the master is not affected by temporary replica outages.
    - **Cons:** creates **eventual consistency**. the replicas are always slightly behind the master. data loss can occur if the master fails before the changes are sent to the replicas.

<hr class="hr-light" />

#### **How to Implement Replication**
This is a quick example of setting up a master with one asynchronous streaming replica in PostgreSQL.

1. **Spin up database instances:** start two PostgreSQL instances. the machines must be network-accessible to each other.
```bash
docker network create pg-net
# Master Node
docker run --name pg-master --network pg-net -e POSTGRES_PASSWORD=password -v pg_master_data:/var/lib/postgresql/data -p 5432:5432 -d postgres

# Standby/Replica Node
docker run --name pg-replica --network pg-net -e POSTGRES_PASSWORD=password -v pg_replica_data:/var/lib/postgresql/data -p 5433:5432 -d postgres
```

2. **Configure the master node:** enable replication settings and create a dedicated replication user on the master.
```bash
# 1. Edit postgresql.conf on the master
listen_addresses = '*'          # Listen on all interfaces
wal_level = replica             # Set Write-Ahead Logging level to at least 'replica'
max_wal_senders = 3             # Allow up to 3 simultaneous replication connections
wal_keep_size = 64MB            # Retain enough WAL segments for the replica to catch up

docker restart pg-master        # Restart the master to save the configuration changes

# 2. Edit pg_hba.conf on the master to allow the replica to connect
# Add a line for replication connections from the replica's IP
host replication repl_user 0.0.0.0/0 md5

# 3. Create a user with replication privileges
psql -U postgres -h localhost -p 5432 -c "CREATE USER repl_user WITH REPLICATION ENCRYPTED PASSWORD 'repl_pass';"
```

3. **Configure the standby node:** the replica is initialized from a base backup of the master and configured to continuously stream changes.
```bash
# 1. Stop the replica container if it's running
docker stop pg-replica

# 2. Remove the data directory on the replica (to replace it with the master's data)
docker run --rm -it --volumes-from pg-replica busybox rm -rf /var/lib/postgresql/data/*

# 3. Take a base backup from the master and feed it to the replica's data directory
docker exec -e PGPASSWORD=repl_pass -it pg-replica pg_basebackup -h pg-master -p 5432 -U repl_user -D /var/lib/postgresql/data -Fp -Xs -R -P

# 4. The -R flag creates a standby.signal file and adds connection info to postgresql.auto.conf
# This is what tells PostgreSQL to start in recovery mode as a standby.

# 5. Start the replica container
docker start pg-replica
```

4. **Verify replication:** writes to the master should now appear on the replica after a short delay (for async).
```sql
-- On Master
CREATE TABLE test_table (id serial PRIMARY KEY, data text);
INSERT INTO test_table (data) VALUES ('Hello from Master!');

-- On Replica (connect to port 5433)
SELECT * FROM test_table; -- Should return the row after a brief moment
```

<hr class="hr-light" />

#### **When to Use Replication**
Replication is a fundamental technique for building robust, scalable, and performant database systems. it is often one of the first steps in a scaling strategy.

**Primary use cases:**
- **High availability & disaster recovery:** if the master database fails, a standby replica can be **promoted** to become the new master, minimizing downtime and data loss.
- **Read scalability:** a common pattern is to direct all **write traffic** to the master and distribute **read traffic** across multiple replicas. this effectively scales read capacity horizontally.
- **Geographic distribution:** placing read replicas in different geographic regions allows users to query a local database, drastically reducing read latency.
- **Data reporting & analytics:** running large, intensive reporting queries on a replica prevents them from consuming resources and impacting the performance of the primary master database.

**The scaling journey (where replication fits):**
1. **Optimize & scale up:** always start here. tune queries, add indexes, and throw more resources (CPU, RAM, fast storage) at your single database server.
2. **Introduce read replicas:** when read operations become the bottleneck, **add replicas**. this is often the first major step towards a distributed architecture and is far simpler than sharding.
3. **Implement caching:** put a cache (Redis, Memcached) in front of your databases to absorb repetitive read loads.
4. **Consider sharding:** only when write operations or dataset size overwhelms a single master node do you need to take the drastic step of **sharding** your database.

<hr class="hr-light" />

#### **Common Pitfalls & Best Practices**

**Common pitfalls:**
- **Ignoring replication lag:** in asynchronous replication, the replica is always behind. an application that reads its own writes must read from the master, or it may see stale data.
- **Promotion procedures:** failing to plan and test the procedure for promoting a replica to master can lead to extended downtime during a real failure.
- **Configuration drift:** manually changing the schema on a replica instead of letting it replicate changes from the master will break replication.
- **Network overhead:** synchronous replication over high-latency network links can bring write performance to a halt.

**Best practices:**
- **Monitor replication lag:** always track how far behind the replicas are. tools like pg_stat_replication in PostgreSQL are essential.
- **Automate failover:** use tools like patroni, pgpool, or cloud-managed services to automate the detection of a master failure and the promotion of a new master.
- **Identical configuration:** ensure the hardware and configuration of replicas are capable of handling the load if they need to become the master.
- **Secure the replication channel:** replication traffic should be encrypted, and replication users should have minimal, strictly necessary privileges.

---

#### **Pros**
- **High availability:** provides a standby node that can take over if the primary master fails.
- **Improved read performance:** read operations can be distributed across multiple replicas, scaling read throughput.
- **Geographic latency reduction:** users can read from a local replica.
- **Disaster recovery:** a replica in a different geographic region can serve as a backup for catastrophic failures.
- **Offloads specialized workloads:** reporting, backup, and analytics queries can be run on a replica without impacting the primary OLTP workload.

<hr class="hr-light" />

#### **Cons**
- **Eventual consistency (async):** replicas are not guaranteed to have the latest data, which can be confusing for applications.
- **Write latency (sync):** synchronous replication increases write latency as the transaction must wait for network round-trips to replicas.
- **Operational complexity:** managing, monitoring, and configuring replication adds a new layer of operational overhead.
- **Storage cost:** requires additional storage capacity for each copy of the data.
- **Complex conflict resolution (multi-master):** resolving write-write conflicts in a multi-master setup is a significant architectural challenge.

---

#### **Real-World Examples**
- **Instagram:** heavily used PostgreSQL replication for read scaling before sharding. they directed all writes to a master and reads to a pool of replicas.
- **GitHub:** experienced a major outage when an erroneous command was written to a MySQL master and instantly replicated to all secondaries, causing data corruption everywhere. this highlights the double-edged sword of replication.
- **Amazon Aurora / AWS RDS:** these cloud database services abstract the complexity of replication away from the user, providing easy-to-create read replicas and automated failover capabilities, making the pattern accessible to everyone.
- **Any large-scale web service:** the read replica pattern is ubiquitous. it is a foundational building block for nearly every high-traffic website and application you use today.